#include <iostream>
#include <vector>
#include <numeric>
#include <algorithm>

#include <iomanip>
#include <random>
#include <CL/sycl.hpp>

#include "utils/profiler.h"
#include "utils/stats.h"
#include "bits.h"

// todo:: add doxygen comments

// TODO:: define a templated type, with concrete overrides for uint8_t, uint16_t, uint32_t, uint64_t, etc...
using sampling_distribution_type = float; /// typically 32-bit wide
using tally_float_type = float; /// typically 80-bit wide, larger than double_t
using bit_vector_type = uint_fast8_t;

// for expression F = ab'c + a'b + bc' + a'bc' + aa'aacc'a, with
// define the number of symbols for X
static constexpr const size_t s_symbols = 3;
// m = 5 products
static constexpr const size_t m_products = 5;
// n = 10 duplicates
static constexpr const size_t n_duplicates = 200000;
// total products = 1e6
static constexpr const std::size_t F_size = m_products * n_duplicates;
// declare a static array for storing the known event X probabilities
using known_event_probabilities = std::array<sampling_distribution_type, s_symbols>;

// TODO:: encode repeating symbols
template<typename T, size_t size>
using products = std::array<T, size>;

// declare as static global std::array to give the compiler hints for compile-time optimizations.
// todo:: investigate whether this has any meaningful performance implications;
static products<bit_vector_type, F_size> F;

static const constexpr known_event_probabilities Px = {
        1e-3,  // P(a)
        1e-4,  // P(b)
        1e-5,  // P(c)
};

// monte carlo sample count
static constexpr const size_t num_samples = 1e7;

// [num_samples] will be generated by sampling each value from Px [num_samples] times. The size of the sampled vector
// will be [num_samples * s_symbols/], but for
//static products<bit_vector_type, num_samples> sampled_x;

// for expression F = ab'c + a'b + bc' + a'bc' + aa'baacc'ab, with:
//
// s = 3 unique symbols (excluding negations)
// n = 2*s = 6 total symbols (including negations)
// m = 5 products
//
// using w=8-bit words to encode n=6 symbols, starting from the MSB, and,
// m = 5 words, we fill out a m=5 element vector,
// where each element encodes one product
// -------------------------------------------------
// |  7  |  6  |  5  |  4  |  3  |  2  |  1  |  0  |
// -------------------------------------------------
// |  a  |  a' |  b  |  b' |  c  |  c' |  -  |  -  |
// -------------------------------------------------
template<size_t size>
static inline void set_F(products<bit_vector_type, size> &F_, const size_t index) {
    // first element: encodes ab'c
    // -------------------------------------------------
    // |  7  |  6  |  5  |  4  |  3  |  2  |  1  |  0  |
    // -------------------------------------------------
    // |  a  |  a' |  b  |  b' |  c  |  c' |  -  |  -  |
    // -------------------------------------------------
    // |  0  |  1  |  1  |  0  |  0  |  1  |  1  |  1  |
    // -------------------------------------------------
    F_[index] = 0b01100111;

    // second element: encodes a'b
    // -------------------------------------------------
    // |  a  |  a' |  b  |  b' |  c  |  c' |  -  |  -  |
    // -------------------------------------------------
    // |  1  |  0  |  0  |  1  |  1  |  1  |  1  |  1  |
    // -------------------------------------------------
    F_[index+1] = 0b10011111;

    // third element: encodes bc'
    // -------------------------------------------------
    // |  a  |  a' |  b  |  b' |  c  |  c' |  -  |  -  |
    // -------------------------------------------------
    // |  1  |  1  |  0  |  1  |  1  |  0  |  1  |  1  |
    // -------------------------------------------------
    F_[index+2] = 0b11011011;

    // fourth element: encodes a'bc'
    // -------------------------------------------------
    // |  a  |  a' |  b  |  b' |  c  |  c' |  -  |  -  |
    // -------------------------------------------------
    // |  1  |  0  |  0  |  1  |  1  |  0  |  1  |  1  |
    // -------------------------------------------------
    F_[index+3] = 0b10011011;

    // fifth element: encodes aa'aacc'
    // repeated terms have no effect
    /** TODO:: [optimization]
     * consider an encoding scheme such that when mutually exclusive events (such as a, a') are both set to 1, this
     * product is masked out of the computation. You can develop this logic by considering how non-existing mutually
     * exclusive events such as (b, b') are being treated in this case. They are both being set to 0, and will be
     * evaluated as such later in the eval step. They would have been removed had this term been encoded like a sparse
     * matrix (removing 0s). So a simple step would be to set the whole term to 0b00000000 when (x, x') is encountered,
     * leaving the empty set to be removed by the sparse-matrix encoding step that should eventually follow.
     *
     * another expensive step is to minimize this term (using boolean reduction) before encoding the term, which is the
     * more general method for the step explained above.
     *
     * another alternative is to bitwise XOR the term with the bitshift of itself (by 1).
     *
     * **/
    // -------------------------------------------------
    // |  a  |  a' |  b  |  b' |  c  |  c' |  -  |  -  |
    // -------------------------------------------------
    // |  0  |  0  |  1  |  1  |  0  |  0  |  1  |  1  |
    // -------------------------------------------------
    F_[index+4] = 0b00010011;
}

// return word-sized object instead of 1-bit.
static inline bool eval(const auto &F_, const auto &sampled_x) {
    // todo:: [optimization]
    // todo:: confirm that any_of will yield and terminate the calculation as soon as any row evals to true.
    // todo:: confirm that any_of does not enforce any execution order for which rows are evaluated first.
    // todo:: together, these two constraints can leverage faster out-of-order, pre-emptive execution
    // todo:: ensure that this intent is communicated/articulated in the sycl kernels or stl functions
    return std::ranges::any_of(F_, [&](bit_vector_type row) {
        return (sampled_x | row) == 0b11111111;
    });
}

template<typename float_type>
static constexpr float_type compute_exact_prob_F(const known_event_probabilities &dist_x) {
    const auto Pa  = static_cast<float_type>(dist_x[0]);
    const auto Pb  = static_cast<float_type>(dist_x[1]);
    const auto Pc  = static_cast<float_type>(dist_x[2]);
    const auto P1  = static_cast<float_type>(1.0);
    const auto Pa_ = P1 - Pa;
    const auto Pb_ = P1 - Pb;
    const auto Pc_ = P1 - Pc;

    // Individual probabilities
    const float_type Pab_c = Pa * Pb_ * Pc;
    const float_type Pa_b  = Pa_ * Pb;
    const float_type Pbc_  = Pb * Pc_;

    // Intersection of A'B and BC' (i.e., A'BC')
    const float_type Pa_bANDPbc_ = Pa_ * Pb * Pc_;

    // Compute P(F)
    const float_type Pf = Pab_c + Pa_b + Pbc_ - Pa_bANDPbc_;

    assert(Pf <= 1.0 && Pf >= 0.0);
    return Pf;
}

static void sample_and_assign_truth_values(const known_event_probabilities &to_sample_from, std::vector<bit_vector_type> &sampled_x) {
    std::random_device rd;
    std::mt19937 stream(372);
    std::uniform_real_distribution<sampling_distribution_type> uniform(0, 1);

    // Use std::generate to fill the vector with random numbers
    std::generate(sampled_x.begin(), sampled_x.end(), [&]() {
        const size_t x_max = 3;
        bit_vector_type sample = 0b00000000;
        for(auto o = 0; o < x_max; o++) {
            const auto shift_by= 2*o + (uniform(stream) > Px[o]);
            sample |= (0b10000000 >> shift_by);
        }
        return sample;
    });
}

int main() {

    // set the function and duplicate the products multiple times
    // todo:: std lambda syntax
    for (auto i = 0; i < n_duplicates; i++) {
        set_F<F_size>(F, i*m_products);
    }

    /**
     * Will be filled by sampling `num_rands` items from `rand_numbers`.
     * Once filled, it represents the truth assignments for all variables in x, each sampled using their known
     * probability distribution [Px]. In essence, we are moving the X sampling logic out of the compute kernels since it
     * is not as efficient to move the support matrix (rand_numbers) (typically float32 or float64) to device, then
     * sample out the truth values, only to discard the support matrix immediately.
     *
     * The benefits here are:
     *      (1) fewer host -> device transfers,
     *      (2) fewer malloc blocks on device,
     *      (3) less work done on device (potential parallelism loss), but it can improve cache coherence if the kernel
     *          is small, both in terms of instruction cache, as well as data-fetches due to cache misses.
     *
     * In the future, as the width of `bit_vector_type` grows from the current (8,16,32,64-bit) blocks to k-bit blocks,
     * the assumptions made here will be challenged. In such cases, we will develop logic to traverse the k-bit wide
     * sampled_X vector as we sample over (k * num_samples) floats from the support vector. The question about
     * generating random numbers inside the kernel is a valid one, and requires more work.
     **/
    //canopy::bits8<num_samples> sampled_x;
    std::vector<bit_vector_type> sampled_x(num_samples);

    std::cout<<canopy::utils::Profiler([&]() {
        sample_and_assign_truth_values(Px, sampled_x);
    }, 1, 0, "generate random number vector, num_samples=1e7, float32").run();

    // Create SYCL buffers
    cl::sycl::queue queue;
    cl::sycl::buffer<bit_vector_type, 1> F_buf(F.data(), cl::sycl::range<1>(F_size));
    cl::sycl::buffer<bit_vector_type, 1> sampled_x_buf(sampled_x.data(), cl::sycl::range<1>(sampled_x.size()));
    cl::sycl::buffer<int, 1> result_buf(cl::sycl::range<1>(1));

    const auto profiler = canopy::utils::Profiler([&]() {
        // Initialize result to zero
        {
            auto acc = result_buf.get_access<cl::sycl::access::mode::discard_write>();
            acc[0] = 0;
        }

        queue.submit([&](cl::sycl::handler& cgh) {
            auto F_acc = F_buf.get_access<cl::sycl::access::mode::read>(cgh);
            auto sampled_x_acc = sampled_x_buf.get_access<cl::sycl::access::mode::read>(cgh);
            auto result_acc = result_buf.get_access<cl::sycl::access::mode::read_write>(cgh);

            cgh.parallel_for<class sample_eval_kernel>(cl::sycl::range<1>(num_samples), [=](cl::sycl::id<1> idx) {
                const size_t i = idx[0];
                const auto sample = sampled_x_acc[i];

                // Evaluate F
                for (auto j = 0; j < F_size; j++) {
                    if ((sample | F_acc[j]) == 0b11111111) {
                        // atomic increment the tally and exit
                        cl::sycl::atomic_ref<int, cl::sycl::memory_order::relaxed, cl::sycl::memory_scope::device, cl::sycl::access::address_space::global_space> count_atomic(result_acc[0]);
                        count_atomic.fetch_add(1);
                        break; // Early exit
                    }
                }
            });
        });
        queue.wait_and_throw();
    }, 2, 0, "F=ab'c+a'b+bc', x=3, term<width>=uint_fast8_t, products=1e6, samples=1e7").run();

    // Retrieve result
    size_t count = 0;
    {
        auto acc = result_buf.get_access<cl::sycl::access::mode::read>();
        count = acc[0];
    }

    const auto known_P = compute_exact_prob_F<tally_float_type>(Px);

    std::cout << std::setprecision(15) << std::scientific;
    std::cout<<"P(a): "<<Px[0]<<"\nP(b): "<<Px[1]<<"\nP(c): "<<Px[2]<<std::endl;

    const auto stats = canopy::utils::SummaryStatistics<tally_float_type, size_t>(count, num_samples, known_P);
    std::cout<<stats;

    std::cout<<profiler; // print the profiler summary

    return 0;
}

// cgh.parallel_for<class sample_eval_kernel>(
//                cl::sycl::nd_range<1>(cl::sycl::range<1>(num_work_groups * work_group_size),
//                                      cl::sycl::range<1>(work_group_size)),
//                [=](cl::sycl::nd_item<1> item) {
//                    size_t global_id = item.get_global_id(0);
//                    size_t local_id = item.get_local_id(0);
//
//                    // Initialize local count
//                    if (local_id == 0) {
//                        local_counts[0] = 0;
//                    }
//                    item.barrier(cl::sycl::access::fence_space::local_space);
//
//                    if (global_id < num_samples) {
//                        // Generate sample
//                        const size_t rand_idx = global_id * s_symbols;
//                        const sampling_distribution_type rand_a = rand_numbers_acc[rand_idx];
//                        const sampling_distribution_type rand_b = rand_numbers_acc[rand_idx + 1];
//                        const sampling_distribution_type rand_c = rand_numbers_acc[rand_idx + 2];
//
//                        bit_vector_type sample = static_cast<bit_vector_type>(
//                                (rand_a > dist_x_acc[0] ? 0b01000000 : 0b10000000) |
//                                (rand_b > dist_x_acc[1] ? 0b00010000 : 0b00100000) |
//                                (rand_c > dist_x_acc[2] ? 0b00000100 : 0b00001000)
//                        );
//
//                        // Evaluate F
//                        bool tally = false;
//                        for (size_t j = 0; j < F_size; j++) {
//                            bit_vector_type row = F_acc[j];
//                            if ((sample | row) == 0b11111111) {
//                                tally = true;
//                                break; // Early exit
//                            }
//                        }
//
//                        // Atomic increment
//                        if (tally) {
//                            //cl::sycl::atomic_ref<int, cl::sycl::memory_order::relaxed, cl::sycl::memory_scope::device, cl::sycl::access::address_space::global_space> count_atomic(result_acc[0]);
//                            //count_atomic.fetch_add(1);
//                            // Use atomic operation on local memory
//                            cl::sycl::atomic_ref<int, cl::sycl::memory_order::relaxed,
//                                    cl::sycl::memory_scope::work_group,
//                                    cl::sycl::access::address_space::local_space> local_count_atomic(
//                                    local_counts[0]);
//                            local_count_atomic.fetch_add(1);
//                        }
//                    }
//
//                    // Ensure all work-items have updated local_counts
//                    item.barrier(cl::sycl::access::fence_space::local_space);
//
//                    // Work-group leader updates the global count
//                    if (local_id == 0) {
//                        // Use atomic operation on global memory
//                        cl::sycl::atomic_ref<int, cl::sycl::memory_order::relaxed,
//                                cl::sycl::memory_scope::device,
//                                cl::sycl::access::address_space::global_space> result_atomic(result_acc[0]);
//                        result_atomic.fetch_add(local_counts[0]);
//                    }
//                });
//    }